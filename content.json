{"meta":{"title":"curiousLei","subtitle":null,"description":"雷答在 Github 上的个人博客","author":"Lei da","url":"http://curiousLei.github.io"},"pages":[],"posts":[{"title":"https搭建(自签名证书)","slug":"https搭建(自签署证书)","date":"2019-01-19T12:49:48.735Z","updated":"2019-01-23T02:21:04.713Z","comments":true,"path":"2019/01/19/https搭建(自签署证书)/","link":"","permalink":"http://curiousLei.github.io/2019/01/19/https搭建(自签署证书)/","excerpt":"","text":"上一篇博客探究了https（ssl）的原理，为了贯彻理论落实于实践的宗旨，本文将记录我搭建https的实操流程，使用Apache2+ubuntu+opensssl 1.使用自签证书配置https一般来讲，正式的上线项目都需要购买域名，并且向权威机构申请证书。但本次工作属于测试环境，所以一切从简，我们使用openssl工具生自签名的CA证书以及服务器证书，来搭建https。具体步骤如下： （1）安装apache2、openssl(ubuntu16.04)安装过程此处不做赘述，很简单。Apache2安装完成并启动后，通过http://ipaddress 来测试，如下图所示，说明安装成功 （2）制作证书生成自签CA证书 生成CA私钥 openssl genrsa -out ca.key 2048 生成CA证书 openssl req -new -x509 -days 3650 -key ca.key -out ca.crt -config /etc/ssl/openssl.cnf openssl.cnf的路径注意填对。最后在当前目录下生成的ca.key即为CA私钥，ca.crt即为CA证书（包含CA公钥） 生成服务器证书 生成服务器私钥 openssl genrsa -out server.key 2048 生成服务器签署申请文件 openssl req -new -out server.csr -key server.key -config /etc/ssl/openssl.cnf 需要填写服务器信息，如实填写即可。需要注意Common Name 需要与openssl.cnf 中配置的域名相对应（alt_names），否则客户端无法验证。该命令最后生成的server.csr即为申请文件。openssl.cnf的具体配置见下文。 在签署证书之前需要确认openssl.cnf中的配置，如下所示： #根据实际情况修改，将match改成optional，否则ca.crt必须与server.csr中的各个字段值一致才能签署[ policy_match ]countryName = optionalstateOrProvinceName = optionalorganizationName = optionalorganizationalUnitName = optionalcommonName = suppliedemailAddress = optional# 确保req下存在以下2行（默认第一行是有的，第2行被注释了）[ req ]distinguished_name = req_distinguished_namereq_extensions = v3_req# 确保req_distinguished_name下没有 0.xxx 的标签，有的话把0.xxx的0. 去掉[ req_distinguished_name ]countryName = Country Name (2 letter code)countryName_default = XXcountryName_min = 2countryName_max = 2stateOrProvinceName = State or Province Name (full name)localityName = Locality Name (eg, city)localityName_default = Default CityorganizationName = Organization Name (eg, company)organizationName_default = Default Company LtdorganizationalUnitName = Organizational Unit Name (eg, section)commonName = Common Name (eg, your name or your server\\&apos;s hostname)commonName_max = 64emailAddress = Email AddressemailAddress_max = 64#添加一行subjectAltName=@alt_names[ v3_req ]# Extensions to add to a certificate requestbasicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName=@alt_names#新增alt_names,注意括号前后的空格，DNS.x 的数量可以自己加#如果没有IP这一项，浏览器使用IP访问时验证无法通过[ alt_names ]IP.1 = 192.168.50.115DNS.1 = dfe.leida.orgDNS.2 = ex.abcexpale.net 使用CA证书和私钥签署服务器证书 openssl ca -in server.csr -out server.crt -cert ca.crt -keyfile ca.key -extensions v3_req -config /etc/ssl/openssl.cnf 直接运行该签署命令，会报错，提示缺少某些文件和目录。在当前目录下把相应的文件及文件夹创建上即可解决，如下 mkdir -p demoCA/newcertstouch ./demoCA/index.txt ./demoCA/serialecho &quot;01&quot;&gt;&gt; ./demoCA/serial 创建完毕后，运行签署命令即可完成服务器证书的制作。当前目录下生成的server.crt即为服务器证书，server.key为服务器私钥 （3）配置apache2 启用ssl模块(此处可使用a2enmod命令) a2enmod ssl 启用ssl站点 a2ensite default-ssl 加入监听端口443(因为https默认采用443端口，有别于http的80) listen 80 443# /etc/apache2/ports.conf中修改成如上所示即可 配置证书以及私钥的路径 SSLCertificateFile /etc/ssl/certs/server.crtSSLCertificateKeyFile /etc/ssl/private/server.key# 在/etc/apache2/sites-available/default-ssl.conf中修改如上参数，确认证书和私钥的路径正确无误 重启apache2，搞定！ 2.使用浏览器测试https上述的制作证书步骤，已经是我测试结束、爬完坑后的正确教程，下文则是填坑记录。 实际上，我一开始按照网上的方法搭建完https后，出现过一些问题。使用浏览器访问https://ipaddress 会跳出如下提示界面实际上此时浏览器已获取到服务器证书server.crt，只是由于某些原因无法验证它。若选择高级选项中的“继续浏览”时，同样可以正常跳转至对应的页面，这时相当于强行让浏览器接受该证书，同时接受服务器公钥。在测试环境下，这样完全OK。但是，强迫症的我还是想让导航栏上出现安全的小锁，红叉叉看着很难受啊。 下面总结记录一下使用浏览器（chrome）测试的过程中遇到的问题以及解决方法 （1）客户端缺少CA证书点击导航栏左侧的感叹号，查看证书，如下图所示此时浏览器已获取到server.crt，由于其对应的CA证书不存在于“受信任的根证书机构”中，所以无法验证server.crt 我们需要将CA证书（上文使用OpenSSL生成的ca.crt）安装至客户端系统中的“受信任的根证书机构”中，保证浏览器可通过此CA证书来验证服务器证书server.crt。安装过程很简单，双击如下所示安装即可 安装结束后，重启浏览器，再次打开证书，如下所示 此时浏览器已经可以使用ca证书来验证server.crt，已完成了很重要的一步，但我的chrome浏览器依然没有出现小锁 （2）缺少使用者备用名称完成上一步后，浏览器的导航栏依然显示不安全，我打开开发者工具，查看security得知，是服务器证书缺少“使用者备用名称”所导致，如下图所示。如何解决这个问题，我参考了这个博客（http://blog.51cto.com/colinzhouyj/1566438 ），即修改openssl.cnf的部分配置，前文“制作证书”步骤中已经整合过此处的配置内容。修改完，重新签署证书，重启apache2，再次运行，Subject Alternative Name missing的问题解决。 （3）IP验证不通过在上一步操作中，我添加完几条DNS之后，发现chrome依然报错，如下图所示我用的是虚拟机环境，没有域名解析，而是直接通过IP来访问站点的，又由于证书中不存在IP信息，是无法跟URL中的IP进行比对的，因此浏览器无法通过证书验证。该问题有两个解决方法 （1）在证书中添加IP地址。在openssl.cnf中配置使用者可选名称时，添加一条IP地址，即可保证浏览器通过对IP的验证，重新签署配置运行后，结果如下 打开证书，使用者可用名称字段如下 （2）使用域名访问。在客户机的host文件中配置域名与IP的映射，直接使用域名来访问站点（证书中包含域名），即可通过验证，如下所示 使用这两种方法的其中一种，迟迟不肯露面的小锁终于出现了，打开security也是一片绿色，大功告成。但是，要注意一点，不同浏览器对于证书的验证方式可能存在差异。按照我的操作，firefox依然无法验证，暂时没细究，但chrome和edge浏览器都可以完美运行。","categories":[],"tags":[]},{"title":"https原理总结","slug":"https原理总结","date":"2019-01-06T09:43:12.851Z","updated":"2019-01-19T12:48:48.066Z","comments":true,"path":"2019/01/06/https原理总结/","link":"","permalink":"http://curiousLei.github.io/2019/01/06/https原理总结/","excerpt":"","text":"最近在公司项目的服务器上做一些内部接口，要求使用https，于是花时间研究了一波。我们熟知的http在传输时未对数据进行加密，在传输一些敏感信息时存在着不小的安全隐患。因此，https在http的基础上加上了SSL（Secure Sockets Layer）加密，以保障数据的安全传输。如今使用的TLS实际上是SSL的升级版本。具体有关https的概念可参考百科https介绍 1.https原理探究https的保障信息安全的机制，其实用一句话就能概括：client与server通过非对称加密来协商一个对称秘钥，然后CS两端使用该对称秘钥来进行数据的加密解密，完成数据交互。所以数据传输时，实际上走的是对称加密。当然理解这句话前提，需要明白对称和非对称加密的原理，本文不做讨论。 原理概况SSL加密机制的大致过程： client发送请求 server返回证书 client验证并取出证书中的公钥 client生成随机数，并使用服务器公钥将其加密，把得到的密文发送给server server使用私钥解密，得到随机数 两端各自通过随机数生成对称秘钥，协商完成 数字证书与数字签名在详细介绍握手环节之前，我想先说说数字数字证书的起因及原理，数字证书是整个SSL加密的核心与纽带。首先，在使用非对称加密传输之前，客户端需要获取服务器公钥，这里存在一种攻击方式，即中间方使用自己的公钥替换服务器的公钥发送给客户端，再通过自己的私钥获取客户端传来的非对称加密内容，从而实现篡改以及窃听。为了方便理解，网上有一张图我直接拿来用了，如下所示。为了防止获取公钥过程遭到第三方的掉包等之类的破坏，于是便有了证书机制，下图为服务器证书的签署以及验证的大致流程。 证书包含三部分内容 证书内容（服务器公钥、服务器信息等） 加密算法（加密算法、哈希算法） 密文（使用哈希算法计算证书内容得到哈希摘要，再使用CA私钥加密该摘要即得到密文，该过程称为数字签名） 验证数字证书 客户端验证服务器证书时，需要获取到你的上一级CA证书，从而得到取CA公钥，使用CA公钥对证书中的密文解密得到哈希摘要，同时客户端使用同样的哈希算法对服务器证书内容计算得到另一个哈希摘要，若这两个摘要相等，则证明证书合法。 上述的哈希签名也称为数字指纹法，该方法的精髓在于，相同的明文通过哈希计算得到的摘要，一定是相同的，而只要两份明文只要有一丝丝区别，其对应的哈希值也是不同的。因此，若第三方替换了证书中的公钥，根据证书内容计算出的新的摘要一定与密文中的摘要有所差异的，故可以轻松地判断证书不合法。 疑问 （1）既然是使用上级CA证书来验证服务器证书，那如何证明上级CA证书的合法性？ 这涉及到一个证书信任链的问题。上级证书通过更高一级的CA根证书来确定其合法性，这是一个递归向上的过程，直到最顶层根证书。顶层CA根证书是整个安全体系的根本。 （2）前文提到的攻击方式，只替换公钥显然是不行，那如果第三方把整个证书都替换成自己的证书（因为CA机构可以给任何人签名，黑客也可以），这样的话客户端的验证是不是可以通过？ 答案当然是否定的，很简单，因为证书内容里的服务器信息是唯一的、不可复制的，例如域名，若替换整个证书，域名也会变成黑客自己的域名，浏览器不会接受域名和请求内容不匹配的证书。比如说，浏览器请求了 baidu.com，结果返回了个google.com的证书，毫无疑问会立即排除掉。 保证了服务器公钥安全抵达客户端手中，后续的对话秘钥的协商便也能顺理成章地进行。因此https所采用的SSL机制是绝对安全的，几乎没有人能够破解。当然，有得必有失，https花费的开销也远高于http。 SSL握手过程 https握手原理图 理解了上文所讲的证书机制，其实SSL加密机制也基本容易理解了，下面细究一下SSL握手过程，此处结合上方交互原理图进行分析（1） Client Helllo。客户端发送初次请求，请求内容包含版本信息，加密套件候选列表，压缩算法候选列表，随机数random_1，扩展字段等信息，以明文传输； （2）服务器选择客户端支持的加密套件、压缩算法、协议版本等，生成随机数random_2； （3）服务器将上述算法以及随机数等发送给客户端； （4）服务器发送服务器数字证书； （5）客户端接收服务器选择的算法以及随机数等，验证数字证书。若证书验证通过，或者用户接受了不可信证书，客户端获取服务器公钥，同时会生成随机数random_3，并使用服务器公钥加密该随机数得到密文； （6）客户端将第五步得到的密文传给服务器，由于公钥加密的内容只能使用私钥解开，所以random_3无法被窃听； （7）Change cipher Spec。客户端通知服务器协商完成； 此时客户端已存有三个随机数random_1、random_2和random_3，前两个是可以被截获的，第三个是私密的，根据这三者可计算得出对话秘钥，即enc_key=Fuc(random_1, random_2, random_3) （8）客户端结合之前所有通信参数的 hash 值与其它相关信息生成一段数据，并使用对话秘钥enc_key和算法将其加密，得到密文encrypted_handshake_message，将其发送给服务器进行验证； （9）服务器使用私钥解密第六步得到的密文，得到随机数random_3，此时服务器也拥有了三个随机数random_1、random_2和random_3，同样可计算出对话秘钥enc_key，至此双方共享对称加密秘钥的目的已达成；计算之前所有接收信息的 hash 值，然后解密客户端发送的 encrypted_handshake_message，验证数据和密钥正确性; （10）类似7和8，服务器通知客户端协商完成，同时计算发送encrypted_handshake_message。客户端以同样的方式验证encrypted_handshake_message，握手完成。 完成握手之后，服务器和客户端都使用相同的对话秘钥enc_key，对消息内容进行加密，实现安全通信。","categories":[],"tags":[]},{"title":"用户评论情感极性判别","slug":"用户评论情感极性判别","date":"2018-07-09T10:34:52.000Z","updated":"2018-07-09T10:35:12.340Z","comments":true,"path":"2018/07/09/用户评论情感极性判别/","link":"","permalink":"http://curiousLei.github.io/2018/07/09/用户评论情感极性判别/","excerpt":"本文章介绍百度点石平台上的一个训练赛的赛题代码，赛题是包括用户评论文字的情感判别的分类问题，赛题链接戳此处 数据预处理 使用测试数据和训练数据生成语料库 import numpy as npimport jiebaimport codecs# 该函数作用是读取文件def load_data(file_path): data_set = [] with open(file_path, &apos;r&apos;) as lines: for line in lines: line=line.strip() values=line.split(&quot;\\t&quot;) data_set.append(values) np.array(data_set) # print(data_set[0]) return data_setdataAll=load_data(&apos;data_train.csv&apos;)dataTest=load_data(&apos;data_test.csv&apos;)csvfile = codecs.open(&quot;fenci_result.csv&quot;, &apos;w&apos;, &apos;utf-8&apos;)#f=open(&apos;fenci_result.txt&apos;,&apos;a&apos;)for item in dataAll: seg_list=jieba.cut(item[2])#使用结巴分词 csvfile.write(&quot; &quot;.join(seg_list))#以空格隔开把分好的词写入文件，形成语料#f.close()for item in dataTest: seg_list=jieba.cut(item[-1]) csvfile.write(&quot; &quot;.join(seg_list))","text":"本文章介绍百度点石平台上的一个训练赛的赛题代码，赛题是包括用户评论文字的情感判别的分类问题，赛题链接戳此处 数据预处理 使用测试数据和训练数据生成语料库 import numpy as npimport jiebaimport codecs# 该函数作用是读取文件def load_data(file_path): data_set = [] with open(file_path, &apos;r&apos;) as lines: for line in lines: line=line.strip() values=line.split(&quot;\\t&quot;) data_set.append(values) np.array(data_set) # print(data_set[0]) return data_setdataAll=load_data(&apos;data_train.csv&apos;)dataTest=load_data(&apos;data_test.csv&apos;)csvfile = codecs.open(&quot;fenci_result.csv&quot;, &apos;w&apos;, &apos;utf-8&apos;)#f=open(&apos;fenci_result.txt&apos;,&apos;a&apos;)for item in dataAll: seg_list=jieba.cut(item[2])#使用结巴分词 csvfile.write(&quot; &quot;.join(seg_list))#以空格隔开把分好的词写入文件，形成语料#f.close()for item in dataTest: seg_list=jieba.cut(item[-1]) csvfile.write(&quot; &quot;.join(seg_list)) 利用语料库，使用word2vec工具，生成可备用的模型，用于将句子转化为向量 from gensim.models import word2vecimport logginglogging.basicConfig(format = &apos;%(asctime)s : %(levelname)s : %(message)s&apos;, level = logging.INFO)sentences = word2vec.Text8Corpus(&quot;fenci_result.csv&quot;) # 加载语料model = word2vec.Word2Vec(sentences, size = 400) # 训练skip-gram模型# 保存模型，以便重用model.save(&quot;corpus.model&quot;)model.wv.save_word2vec_format(&quot;corpus.model.bin&quot;, binary = True) 数据训练与测试 感觉训练方式很简陋，有待改善 #本程序用来测试模型#coding=utf-8 import reimport numpy as npimport jiebafrom gensim.models import word2vecimport loggingimport codecsfrom sklearn.decomposition import PCAfrom sklearn.model_selection import train_test_splitfrom sklearn import svmfrom sklearn.metrics import accuracy_score,confusion_matrix, f1_score, precision_score, recall_score, \\ roc_curve # 导入指标库import prettytable # 导入表格库# 该函数作用是读取文件def load_data(file_path): data_set = [] with open(file_path, &apos;r&apos;) as lines: for line in lines: line=line.strip() values=line.split(&quot;\\t&quot;) data_set.append(values) np.array(data_set) # print(data_set[0]) return data_set#写文件def write_result(array, outpuFilePath): with open(outpuFilePath, &apos;w&apos;) as output_file: for i in range(len(array)): output_file.write(&quot;%d,%d\\n&quot; % (i+1,array[i]))#将句子转化为向量def getWordVecs(wordList): vecs = [] for word in wordList: word = word.strip() try: vecs.append(model[word]) except KeyError: continue # vecs = np.concatenate(vecs) return np.array(vecs, dtype = &apos;float&apos;)model = word2vec.KeyedVectors.load_word2vec_format(&quot;corpus.model.bin&quot;, binary = True)# segList=jieba.cut(&apos;烤鸭还是不错的，别的菜没什么特殊的&apos;)# resultList = getWordVecs(segList)# print(sum(np.array(resultList))/2)dataAll=load_data(&apos;data_train.csv&apos;)X=[]y=[]dataAll=np.array(dataAll[:1500])for item in dataAll: #temp=int(item[-1]) #y.append(temp if temp!=0 else 1)#把0都替换成1，先对2和1进行分类 y.append(int(item[-1])) segList=jieba.cut(item[2]) vecList=getWordVecs(segList) if len(vecList) != 0: X.append(sum(np.array(vecList))/len(vecList))X=X[:]x_train=np.array(X)y_train=np.array(y)print(x_train)print(y_train)# x_train = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2], [2, 1], [3, 2]])# print(x_train)# 使用sklearn的PCA进行维度转换model_pca = PCA(n_components=0.95) # 建立PCA模型对象model_pca.fit(x_train) # 将数据集输入模型#model_pca.transform(x_train) # 对数据集进行转换映射newX=model_pca.fit_transform(x_train)#进行转换映射，并将转换后的赋给newXcomponents = model_pca.components_ # 获得转换后的所有主成分(不明白什么意思)components_var = model_pca.explained_variance_ # 获得各主成分的方差components_var_ratio = model_pca.explained_variance_ratio_ # 获得各主成分的方差占比print(&quot;\\n主成分分析：&quot;)print (components) # 打印输出前2个主成分print (len(components_var)) # 打印输出所有主成分的方差print (components_var_ratio) # 打印输出所有主成分的方差占比print(len(newX))print(len(newX[0]))X_train, X_test, y_train, y_test = train_test_split(newX, y_train, test_size=.3, random_state=0)clf = svm.SVC(C=1, kernel=&apos;linear&apos;,decision_function_shape=&apos;ovr&apos;)clf.fit(X_train, y_train)y_hat=clf.predict(X_test)##评价指标accuracy_s = accuracy_score(y_test, y_hat) # 准确率precision_s = precision_score(y_test, y_hat, average=&apos;macro&apos;) # 精确度recall_s = recall_score(y_test, y_hat, average=&apos;macro&apos;) # 召回率f1_s = f1_score(y_test, y_hat, average=&apos;weighted&apos;) # F1得分print(&apos;Accuracy:&apos;)print(accuracy_s)print(&apos;Precision:&apos;)print(precision_s)print(&apos;Recall:&apos;)print(recall_s)print(&apos;f-measure:&apos;)print(f1_s)##混淆矩阵confusion_m = confusion_matrix(y_test,y_hat) # 获得混淆矩阵confusion_matrix_table = prettytable.PrettyTable() # 创建表格实例confusion_matrix_table.add_row(confusion_m[0, :]) # 增加第一行数据confusion_matrix_table.add_row(confusion_m[1, :]) # 增加第二行数据confusion_matrix_table.add_row(confusion_m[2, :]) # 增加第三行数据print (&apos;confusion matrix&apos;)print (confusion_matrix_table) # 打印输出混淆矩阵write_result(y_hat,&apos;print.csv&apos;) 预测阶段 使用所有训练数据训练模型并对test数据进行预测 #本程序用来进行预测#coding=utf-8 import reimport numpy as npimport jiebafrom gensim.models import word2vecimport loggingimport codecsfrom sklearn.decomposition import PCAfrom sklearn.model_selection import train_test_splitfrom sklearn import svm# 该函数作用是读取文件def load_data(file_path): data_set = [] with open(file_path, &apos;r&apos;) as lines: for line in lines: line=line.strip() values=line.split(&apos;\\t&apos;) data_set.append(values) np.array(data_set) # print(data_set[0]) return data_set#写文件def write_result(array, outpuFilePath): with open(outpuFilePath, &apos;w&apos;) as output_file: for i in range(len(array)): output_file.write(&quot;%d,%d\\n&quot; % (i+1,array[i]))#将句子转化为向量def getWordVecs(wordList): vecs = [] for word in wordList: word = word.strip() try: vecs.append(model[word]) except KeyError: continue # vecs = np.concatenate(vecs) return np.array(vecs, dtype = &apos;float&apos;)#对预测数据进行处理def preDataHandle(): preData=load_data(&apos;data_test.csv&apos;) #exit(0) xPre=[] i=0 k=0 for item in preData: i+=1 s=&apos;&apos; for j in range(len(item)): if(j&gt;1): s=&quot;%s%s&quot;%(s,item[j]) segList=jieba.cut(s) vecList=getWordVecs(segList) if len(vecList) != 0: xPre.append(sum(np.array(vecList))/len(vecList)) else: k+=1 print(&apos;存在vecList长度为0的情况&apos;) print(item) x_pre=np.array(xPre) model_pca = PCA(n_components=factorNum) # 建立PCA模型对象 model_pca.fit(x_pre) # 将数据集输入模型 x_pre=model_pca.fit_transform(x_pre)#进行转换映射 return x_premodel = word2vec.KeyedVectors.load_word2vec_format(&quot;corpus.model.bin&quot;, binary = True)dataAll=load_data(&apos;data_train.csv&apos;)X=[]y=[]#dataAll=np.array(dataAll[:1500])for item in dataAll: print(item) y.append(int(item[-1])) segList=jieba.cut(item[2]) vecList=getWordVecs(segList) if len(vecList) != 0: X.append(sum(np.array(vecList))/len(vecList)) else: print(item)X=X[:]x_train=np.array(X)y_train=np.array(y)model_pca = PCA(n_components=0.95) # 建立PCA模型对象model_pca.fit(x_train) # 将数据集输入模型#model_pca.transform(x_train) # 对数据集进行转换映射newX=model_pca.fit_transform(x_train)#进行转换映射，并将转换后的赋给newXfactorNum=len(newX[0])clf = svm.SVC(C=1, kernel=&apos;linear&apos;,decision_function_shape=&apos;ovr&apos;)clf.fit(newX, y_train)x_pre=preDataHandle()y_pre=clf.predict(x_pre)write_result(y_pre,&apos;output.csv&apos;)print(&apos;Project has been finished successfully!&apos;) 比赛平台上计算出的结果f1-score为0.7249，很低，希望再接再厉","categories":[],"tags":[]},{"title":"Hello,Hexo!","slug":"Hello-Hexo","date":"2018-07-09T06:58:15.000Z","updated":"2018-07-09T08:35:20.314Z","comments":true,"path":"2018/07/09/Hello-Hexo/","link":"","permalink":"http://curiousLei.github.io/2018/07/09/Hello-Hexo/","excerpt":"常见命令hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面（新建了一个md文件组,但目前不知道怎么用）hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本hexo clean #清理public的内容","text":"常见命令hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面（新建了一个md文件组,但目前不知道怎么用）hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本hexo clean #清理public的内容 缩写hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy 组合命令hexo s -g #生成并本地预览hexo d -g #生成并上传","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2018-07-09T06:28:05.440Z","updated":"2018-07-09T06:28:05.440Z","comments":true,"path":"2018/07/09/hello-world/","link":"","permalink":"http://curiousLei.github.io/2018/07/09/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}